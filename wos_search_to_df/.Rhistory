}
# Function to retrieve WoS author names from dataframes to chars
fetch_author_names <- function(x) {
return(paste(x[, 'wosStandard'], collapse = "; "))
}
# Function to retrieve WoS times cited counts
fetch_times_cited <- function(x) {
row <- x[x$db == 'WOS', ]
return(row$count)
}
# Apply the functions above to specific columns
M$UT <- sapply(M$UT, wos_to_isi)
M$DT <- sapply(records$types, vector_to_char)
M$AU <- sapply(records$names.authors, fetch_author_names)
M$TC <- sapply(records$citations, fetch_times_cited)
M$DE <- sapply(records$keywords.authorKeywords, vector_to_char)
View(M)
vector_to_char <- function(x) {
if(length(x) == 0) {
return("")
} else {
return(paste(x, collapse = "; "))
}
}
M$DE <- sapply(records$keywords.authorKeywords, vector_to_char)
print(M$DE)
# Function to convert vectors to characters
vector_to_char <- function(x) {
if(is.vector(x)) {
return(paste(x, collapse = "; "))
} else if (is.character(x)){
return("Test")
}
}
M$DE <- sapply(records$keywords.authorKeywords, vector_to_char)
print(M$DE)
vector_to_char <- function(x) {
if(is.vector(x)) {
return(paste(x, collapse = "; "))
} else if (length(x) == 0){
return("Test")
}
}
M$DE <- sapply(records$keywords.authorKeywords, vector_to_char)
print(M$DE)
vector_to_char <- function(x) {
if(is.vector(x)) {
return(paste(x, collapse = "; "))
} else if (is.character(c)){
print("It's a char!")
}
}
M$DE <- sapply(records$keywords.authorKeywords, vector_to_char)
vector_to_char <- function(x) {
if(is.vector(x)) {
return(paste(x, collapse = "; "))
} else if (is.character(x)){
print("It's a char!")
}
}
M$DE <- sapply(records$keywords.authorKeywords, vector_to_char)
print(M$DE)
# Function to convert vectors to characters
vector_to_char <- function(x) {
if(is.vector(x)) {
return(paste(x, collapse = "; "))
} else if (is.character(x)) {
print("It's a char!")
}
}
M$DE <- sapply(records$keywords.authorKeywords, vector_to_char)
print(M$DE)
View(M)
vector_to_char <- function(x) {
if(length(x) == 0) {
return("Empty")
} else if (is.vector(x)) {
return(paste(x, collapse = "; "))
}
}
M$DE <- sapply(records$keywords.authorKeywords, vector_to_char)
View(M)
biblioNetwork(M, analysis = "co-occurrences", network = "author_keywords")
library(bibliometrix)
biblioNetwork(M, analysis = "co-occurrences", network = "author_keywords")
some_object <- data("isiCollection", package = "bibliometrixData")
biblioNetwork(some_object, analysis = "co-occurrences", network = "author_keywords")
vector_to_char <- function(x) {
if(length(x) == 0) {
return("")
} else if (is.vector(x)) {
return(paste(x, collapse = "; "))
}
}
M$DE <- sapply(records$keywords.authorKeywords, vector_to_char)
print(M$DE)
biblioNetwork(some_object, analysis = "co-occurrences", network = "author_keywords")
biblioNetwork(some_object, analysis = "co-occurrences", network = "author_keywords")
# View the result as a dataframe
View(records)
# Vizualise the dataframe
pub_years <- table(records$source.publishYear)
barplot(pub_years, col="#B175E1", border="#B175E1")
# Load necessary libraries
library(httr)
library(jsonlite)
# Load the Web of Science Starter API key
source('apikeys.R')
# Define your search query
search_query_1 <- "TS=vosviewer"
# Set up the parameters for the API request
params <- list(
'db' = 'WOS',
'limit' = 50,
'q' = URLencode(search_query_1),
'page' = 1
)
# Make the initial GET request to the Web of Science Starter API
response <- GET(
"https://api.clarivate.com/apis/wos-starter/v1/documents",
query = params,
add_headers(`X-ApiKey` = starter_apikey)
)
# Parse the initial JSON content of the response
initial_content <- content(response, as = "text", encoding = "UTF-8")
initial_json <- fromJSON(initial_content, flatten = TRUE)
records_1 = initial_json$hits
# Calculate the number of necessary requests to retrieve all the data
documents_found <- initial_json$metadata$total
requests_required <- ((documents_found - 1 ) %/% params$limit) + 1
# Send subsequent API requests
if (requests_required > 1) {
for (i in 2:requests_required) {
params$page <- i
response <- GET(
"https://api.clarivate.com/apis/wos-starter/v1/documents",
query = params,
add_headers(`X-ApiKey` = starter_apikey)
)
subsequent_content <- content(response, as = "text", encoding = "UTF-8")
subsequent_json <- fromJSON(subsequent_content, flatten = TRUE)
records_1 <- merge(records_1, subsequent_json$hits, all = TRUE)
print(paste("Request #", i, " of ", requests_required, sep=""))
}
}
# Define your search query 2
search_query_2 <- "TS=citespace"
# Set up the parameters for the API request
params <- list(
'db' = 'WOS',
'limit' = 50,
'q' = URLencode(search_query_2),
'page' = 1
)
# Make the initial GET request to the Web of Science Starter API
response <- GET(
"https://api.clarivate.com/apis/wos-starter/v1/documents",
query = params,
add_headers(`X-ApiKey` = starter_apikey)
)
# Parse the initial JSON content of the response
initial_content <- content(response, as = "text", encoding = "UTF-8")
initial_json <- fromJSON(initial_content, flatten = TRUE)
records_2 = initial_json$hits
# Calculate the number of necessary requests to retrieve all the data
documents_found <- initial_json$metadata$total
requests_required <- ((documents_found - 1 ) %/% params$limit) + 1
# Send subsequent API requests
if (requests_required > 1) {
for (i in 2:requests_required) {
params$page <- i
response <- GET(
"https://api.clarivate.com/apis/wos-starter/v1/documents",
query = params,
add_headers(`X-ApiKey` = starter_apikey)
)
subsequent_content <- content(response, as = "text", encoding = "UTF-8")
subsequent_json <- fromJSON(subsequent_content, flatten = TRUE)
records_2 <- merge(records_2, subsequent_json$hits, all = TRUE)
print(paste("Request #", i, " of ", requests_required, sep=""))
}
}
# Define your search query
search_query_3 <- "TS=(bibliometrix)"
# Set up the parameters for the API request
params <- list(
'db' = 'WOS',
'limit' = 50,
'q' = URLencode(search_query_3),
'page' = 1
)
# Make the initial GET request to the Web of Science Starter API
response <- GET(
"https://api.clarivate.com/apis/wos-starter/v1/documents",
query = params,
add_headers(`X-ApiKey` = starter_apikey)
)
# Parse the initial JSON content of the response
initial_content <- content(response, as = "text", encoding = "UTF-8")
initial_json <- fromJSON(initial_content, flatten = TRUE)
records_3 = initial_json$hits
# Calculate the number of necessary requests to retrieve all the data
documents_found <- initial_json$metadata$total
requests_required <- ((documents_found - 1 ) %/% params$limit) + 1
# Send subsequent API requests
if (requests_required > 1) {
for (i in 2:requests_required) {
params$page <- i
response <- GET(
"https://api.clarivate.com/apis/wos-starter/v1/documents",
query = params,
add_headers(`X-ApiKey` = starter_apikey)
)
subsequent_content <- content(response, as = "text", encoding = "UTF-8")
subsequent_json <- fromJSON(subsequent_content, flatten = TRUE)
records_3 <- merge(records_3, subsequent_json$hits, all = TRUE)
print(paste("Request #", i, " of ", requests_required, sep=""))
}
}
# Create vizualisations from the dataframe
pub_years_vos <- table(records_1$source.publishYear)
pub_years_cs <- table(records_2$source.publishYear)
pub_years_bmbs <- table(records_3$source.publishYear)
df <- merge(pub_years_vos, pub_years_cs, by = 1, all = TRUE, )
df <- merge (df, pub_years_bmbs, all = TRUE)
row.names(df) <- final_table$Var1
# Create vizualisations from the dataframe
pub_years_vos <- table(records_1$source.publishYear)
pub_years_cs <- table(records_2$source.publishYear)
pub_years_bmbs <- table(records_3$source.publishYear)
df <- merge(pub_years_vos, pub_years_cs, by = 1, all = TRUE, )
df <- merge (df, pub_years_bmbs, all = TRUE)
row.names(df) <- final_table$Var1
# Create vizualisations from the dataframe
pub_years_vos <- table(records_1$source.publishYear)
pub_years_cs <- table(records_2$source.publishYear)
pub_years_bmbs <- table(records_3$source.publishYear)
df <- merge(pub_years_vos, pub_years_cs, by = 1, all = TRUE, )
df <- merge (df, pub_years_bmbs, all = TRUE)
row.names(df) <- df$Var1
df <- df[order(row.names(df)), , drop = FALSE]
df$Var1 <- NULL
coul = c("#93FF9E", "#B175E1", "#F0FE4F")
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF"
)
opar = par(oma = c(0,0,0,0), mar = c(0,0,0,0), new = TRUE)
legend("topright",
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
# Define your search query
search_query_3 <- "TS=(bibliometrix or biblioshiny)"
# Set up the parameters for the API request
params <- list(
'db' = 'WOS',
'limit' = 50,
'q' = search_query_3,
'page' = 1
)
# Make the initial GET request to the Web of Science Starter API
response <- GET(
"https://api.clarivate.com/apis/wos-starter/v1/documents",
query = params,
add_headers(`X-ApiKey` = starter_apikey)
)
response <- GET(
"https://api.clarivate.com/apis/wos-starter/v1/documents",
query = params,
add_headers(`X-ApiKey` = starter_apikey)
)
# Parse the initial JSON content of the response
initial_content <- content(response, as = "text", encoding = "UTF-8")
initial_json <- fromJSON(initial_content, flatten = TRUE)
records_3 = initial_json$hits
# Calculate the number of necessary requests to retrieve all the data
documents_found <- initial_json$metadata$total
requests_required <- ((documents_found - 1 ) %/% params$limit) + 1
# Send subsequent API requests
if (requests_required > 1) {
for (i in 2:requests_required) {
params$page <- i
response <- GET(
"https://api.clarivate.com/apis/wos-starter/v1/documents",
query = params,
add_headers(`X-ApiKey` = starter_apikey)
)
subsequent_content <- content(response, as = "text", encoding = "UTF-8")
subsequent_json <- fromJSON(subsequent_content, flatten = TRUE)
records_3 <- merge(records_3, subsequent_json$hits, all = TRUE)
print(paste("Request #", i, " of ", requests_required, sep=""))
}
}
pub_years_bmbs <- table(records_3$source.publishYear)
df <- merge(pub_years_vos, pub_years_cs, by = 1, all = TRUE, )
df <- merge (df, pub_years_bmbs, all = TRUE)
row.names(df) <- df$Var1
df <- df[order(row.names(df)), , drop = FALSE]
df$Var1 <- NULL
coul = c("#93FF9E", "#B175E1", "#F0FE4F")
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF"
)
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF"
)
opar = par(oma = c(0,0,0,0), mar = c(0,0,0,0), new = TRUE)
legend("top",
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
par(opar)
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF",
labels()
)
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF",
labels(df)
)
coul = c("#93FF9E", "#B175E1", "#F0FE4F")
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF",
labels(df)
)
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF",
labels = c("20")
)
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF",
)
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF",
labels = df
)
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF",
)
p <- barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF",
)
text(x = p, y = df + 0.5, labels = df)
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF",
)
legend("top",
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
legend("topleft",
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF",
)
legend("topleft",
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
legend("bottomleft",
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
par(opar)
opar = par(oma = c(0,0,0,0), mar = c(10,10,10,10), new = TRUE)
par(opar)
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF",
)
legend(x = 1, y = 1,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
legend(x = 100, y = 1,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
legend(x = -100, y = 1,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
legend(x = 0, y = 1,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
par(opar)
legend(x = 0, y = 10,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
legend(x = -10, y = 1,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
legend(x = 10, y = 10,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
legend(x = 10,
y = 10,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
legend(x = 10,
y = 20,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
legend(x = 10,
y = 300,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
legend(x = 1,
y = 900,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF",
)
legend(x = 1,
y = 900,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
legend(x = 0,
y = 900,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
legend(x = 0,
y = 1300,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
barplot(
t(as.matrix(df)),
beside = TRUE,
main = "Dynamics comparison for the topics",
col = coul,
border = "#FFFFFF",
)
legend(x = 0,
y = 1300,
legend = c(search_query_1, search_query_2, search_query_3),
fill = coul
)
library(bibliometrix)
biblioshiny()
