# Load necessary libraries
library(httr)
library(jsonlite)

# Load the Web of Science Starter API key
source('apikeys.R')

# Define your search query
search_query <- "TS=Bibliometric*"

# Set up the parameters for the API request
params <- list(
  'databaseId' = 'WOS',
  'count' = 100,
  'usrQuery' = search_query,
  'firstRecord' = 1
)

# Make the initial GET request to the Web of Science Expanded API
response <- GET(
  "https://wos-api.clarivate.com/api/wos",
  query = params,
  add_headers(`X-ApiKey` = expanded_apikey)
)

# Parse the initial JSON content of the response
initial_content <- content(response, as = "text", encoding = "UTF-8")
initial_json <- fromJSON(initial_content, flatten = TRUE)
records = initial_json$Data$Records$records$REC

# Calculate the number of necessary requests to retrieve all the data
documents_found <- initial_json$QueryResult$RecordsFound
requests_required <- ((documents_found - 1 ) %/% params$count) + 1

# Send subsequent API requests
if (requests_required > 1) {
  for (i in 2:requests_required) {
    params$firstRecord <- ((i - 1) * 100) + 1 
    response <- GET(
      "https://wos-api.clarivate.com/api/wos",
      query = params,
      add_headers(`X-ApiKey` = expanded_apikey)
    )
    subsequent_content <- content(response, as = "text", encoding = "UTF-8")
    subsequent_json <- fromJSON(subsequent_content, flatten = TRUE)
    records <- merge(records, subsequent_json$Data$Records$records$REC, all = TRUE)
    print(paste("Request #", i, " of ", requests_required, sep=""))
  }
}

# View the result as a dataframe
View(records)


# Reformat the dataframe for Bibliometrix
M <- records[, c('UID', 'static_data.summary.pub_info.pubyear')]
names(M) <- c('UT', 'PY')
M$DB <- rep('WOS', times = nrow(M))

# Function to convert the UT column values into Bibliometrix format
wos_to_isi <- function(x) {
  return(gsub('WOS:', 'ISI', x))
}

# Function to convert vectors to characters
vector_to_char <- function(x) {
  if(length(x) == 0) {
    return("")
  } else if (is.vector(x)) {
    return(paste(x, collapse = "; "))
  }
}

# Function to retrieve WoS author names from dataframes to chars
fetch_author_names <- function(x) {
  if(is.data.frame(x)) {
    return(paste(x[, "full_name"], collapse = "; "))
  } else if(is.list(x)) {
    return(x$full_name)
  } else {
    return("")
  }
}

# Function to retrieve WoS times cited counts
fetch_times_cited <- function(x) {
  row <- x[x$coll_id == 'WOS', ]
  return(row$local_count)
}

# Function to retrieve the source title
fetch_source_title <- function(x) {
  row <- x[x$type == 'source', ]
  return(row$content)
}

# Function to retrieve the source title abbreviation
fetch_source_abbreviation <- function(x) {
  if('abbrev_iso' %in% x$type) {
    row <- x[x$type == 'abbrev_iso', ]
    return(row$content)
  } else {
    return("")
  }
}

# Function to retrieve the abstract text
fetch_abstract <- function(x) {
  if(length(x) == 0) {
    return("")
  } else {
    return(x)
  }
}

fetch_author_names_for_c1 <- function(x) {
  if(is.data.frame(x)) {
    return(paste(x[, "names.name.full_name"], collapse = "; "))
  } else if(is.list(x)) {
    return(x$names$name$full_name)
  } else {
    return("")
  }
}


fetch_org_names <- function(x) {
  org_df <- x$address_spec.organizations.organization[[1]]
  if("Y" %in% org_df$pref) {
    row <- org_df[org_df$pref == "Y", ]
    return(row$content[-1])
  } else {
    org_df <- x$address_spec$organizations$organization
    if("Y" %in% org_df$pref) {
      row <- org_df[org_df$pref == "Y", ]
      return(row$content[-1])
    }
  }
}

fetch_c1 <- function(x) {
  if(is.data.frame(x)) {
    c1 = list()
    for(i in c(1:nrow(x))) {
      org <- fetch_org_names(x[i,])
      authors <- fetch_author_names_for_c1(x[i,])
      c1[i] <- paste("[", authors, "] ", org, sep = "")
    }
    return(paste(c1, collapse = "; "))
  } else {
    org <- fetch_org_names(x)
    authors <- fetch_author_names_for_c1(x)
    return(paste("[", authors, "] ", org, sep = ""))
  }
}


# Apply the functions above to specific columns
M$UT <- sapply(M$UT, wos_to_isi)
M$DT <- sapply(records$static_data.summary.doctypes.doctype, vector_to_char)
M$AU <- sapply(records$static_data.summary.names.name, fetch_author_names)
M$TC <- sapply(
  records$dynamic_data.citation_related.tc_list.silo_tc,
  fetch_times_cited
  )
M$DE <- sapply(
  records$static_data.fullrecord_metadata.keywords.keyword,
  vector_to_char
  )
M$ID <- sapply(records$static_data.item.keywords_plus.keyword, vector_to_char)
M$SO <- sapply(records$static_data.summary.titles.title, fetch_source_title)
M$JI <- sapply(
  records$static_data.summary.titles.title,
  fetch_source_abbreviation
  )
M$AB <- sapply(
  records$static_data.fullrecord_metadata.abstracts.abstract.abstract_text.p,
  fetch_abstract
  )
M$C1 <- sapply(records$static_data.fullrecord_metadata.addresses.address_name, fetch_c1)

# Dumbest debugging area
some_object <- records
test_value <- fetch_c1(some_object)

print(some_object)
print(typeof(some_object))
print(is.data.frame(some_object))
View(some_object)

View(M)

library(bibliometrix)
biblioshiny()

biblioAnalysis(M, sep = "; ")
biblioNetwork(M, analysis = "co-occurrences", network = "author_keywords")
bradford(M)
missingData(M, sep = ";")
